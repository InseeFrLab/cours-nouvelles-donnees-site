---
title: "Application 1 - Données spatiales"
format: html
---

# Préparation de l'environnement



### Import des données dans votre work locale

- Les données « Demandes de Valeurs Foncières », ou **DVF**, qui recensent l'ensemble des ventes de biens fonciers réalisées au cours des dernières années, en métropole et dans les départements et territoires d'outre-mer — sauf à Mayotte et en Alsace-Moselle. Les biens concernés peuvent être bâtis (appartement et maison) ou non bâtis (parcelles et exploitations). Les données sont produites par la Direction générale des finances publiques. Elles proviennent des actes enregistrés chez les notaires et des informations contenues dans le cadastre. Cette base a été filtrée de manière à être la plus pédagogique possible pour cette formation.
- Les données spatiales carroyées à 200m, produites par l'Insee à partir du dispositif **Filosofi**, contentant des informations socio-économiques sur les ménages.
- 3 contours géographiques : 
  - La commune de Malakoff
  - La commune de Montrouge
  - Le "Triangle d'or" de Malakoff (autrement dit, son centre-ville à peu de choses près)

```{r}
system("mc cp s3/projet-formation/nouvelles-sources/data/geoparquet/dvf.parquet dvf.parquet")
system("mc cp s3/projet-formation/nouvelles-sources/data/geoparquet/carreaux.parquet carreaux.parquet")
system("mc cp s3/projet-formation/nouvelles-sources/data/triangle.geojson triangle.geojson")
system("mc cp s3/projet-formation/nouvelles-sources/data/malakoff.geojson malakoff.geojson")
system("mc cp s3/projet-formation/nouvelles-sources/data/montrouge.geojson montrouge.geojson")
```

### Chargement des libraries nécessaires : 

```{r}
#| message: false
#| warning: false
#| echo: false

library(duckdb)
library(glue)
library(dplyr)
library(mapview)
```

### Variables globales pour l'applications : 

```{r}
cog_malakoff <- "92046"
cog_montrouge <- "92049"
```


### Import et visualisation des contours géographiques : 


```{r}

triangle <- sf::st_read("triangle.geojson", quiet=TRUE)
malakoff <- sf::st_read("malakoff.geojson", quiet=TRUE)
montrouge <- sf::st_read("montrouge.geojson", quiet=TRUE)

mapview(malakoff) + mapview(triangle, col.regions = "#ffff00")

mapview(montrouge)

```

### Préparation de DuckDB

**DuckDB** est un moteur de base de données analytique en mémoire, optimisé pour les requêtes SQL sur des données volumineuses, particulièrement adapté aux fichiers plats comme Parquet ou CSV, et intégrable dans des langages comme Python, R ou SQL.

On commence par :

- Créer une connexion DuckDB
- Installer et charger les extensions spatiales (car DVF et les données carroyées sont des données spatiales).

```{r}
#| message: false
#| warning: false
#| echo: false

con <- dbConnect(duckdb::duckdb())
dbExecute(con, "INSTALL spatial;")
dbExecute(con, "LOAD spatial;")

```

# Partie 1 : Prix immobiliers à Malakoff et à Montrouge

Dans cette partie, l'objectif est d'extraire de l'informations d'une base de données volumineuse à l'aide de DuckDB. Pour le moment, le caractère spatial des données est mis de côté : on découvre et on traite les données via des requêtes attributaires classiques.

Tentons de comparer la médiane des prix des transactions immobilières à Malakoff et à Montrouge.


### Description des données DVF

Tout d'abord, il convient de se familiariser avec les données. Les requêtes ci-dessous permettent d'obtenir des informations primordiale de manière très rapide et sans nécessité de charger l'ensemble des données dans la mémoire vive.


Description des variables : 

```{r}
describe_dvf <- dbGetQuery(con, "DESCRIBE SELECT * FROM read_parquet('dvf.parquet')")
print(describe_dvf)
```

Visualisation des 10 premières lignes : 

```{r}
preview <- dbGetQuery(con, "SELECT * FROM read_parquet('dvf.parquet') LIMIT 10")
print(preview)
```


Que contient le champ `nature_mutation` ? (il a été filtré au ventes classiques pour simplifié cette application ; les vraies données sont plus riches).
```{r}
dbGetQuery(con, "SELECT DISTINCT nature_mutation FROM read_parquet('dvf.parquet')")
```

Vérification des bornes min et max des prix des transactions : 

```{r}
dbGetQuery(con, "
        SELECT
            MIN(valeur_fonciere) AS min_valeur,
            MAX(valeur_fonciere) AS max_valeur
        FROM read_parquet('dvf.parquet')
           ")
```


Requête de calcul des prix médians des transactions à Malakoff et à Montrouge : 

- Filtre des seules transactions effectuées à Montrouge ou Malakoff (requête attributaire, pas de traitement spatial ici).
- Calculs groupés de la médiane par communes des montants des transactions

```{r}
query1 <- glue("
    FROM read_parquet('dvf.parquet')
    SELECT
        code_commune,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY valeur_fonciere) AS mediane_valeur_fonciere
    WHERE code_commune IN ('{cog_malakoff}', '{cog_montrouge}')
    GROUP BY code_commune
")

result1 <- dbGetQuery(con, query1)
print(result1)

```


Conclusion : les biens vendus à Montrouge (dans notre base) ont une médiane un peu plus élevée qu'à Malakoff.



# Partie 2 : les prix immobiliers à Malakoff, dans le centre et en-dehors.

À présent, nous souhaitons avoir des informations sur les transactions effectuées dans le « fameux » Triangle d'Or de Malakoff (plus prosaïquement, dans son centre-ville commerçant).

Comme il n'est pas possible de distringuer cette zone par requêtes attributaires, nous proposons de : 

- Via `DuckDB`, extraire les transactions de l'ensemble de la commune de Malakoff tout en conservant leur caractère spatial (chaque transaction correspond à un point géographique, avec ses coordonnées xy).
- Utiliser localement le package `sf` pour distinguer spatialement les transactions effectuées à l'intérieur ou à l'extérieur du Triangle d'Or (dont nous fournissons les contours).
- Calculer la médiane des prix dans les deux sous-zones.


On extrait les transactions de Malakoff. Pour information, dans le fichier `dvf.parquet`, les coordonnées spatiales sont stockées dans un format binaire spécifique (Well-Known Binary - WKB). Ce format est efficace pour le stockage et les calculs, mais n'est pas directement lisible ou interprétable par les humains.

En transformant ces géométries en une représentation texte lisible (Well-Known Text - WKT) avec `ST_AsText`, on rend les données spatiales faciles à afficher, interpréter ou manipuler dans des contextes qui ne supportent pas directement les formats binaires géospatiaux.

```{r}
query2 <- glue("
    FROM read_parquet('dvf.parquet')
    SELECT
        code_commune,
        valeur_fonciere,
        ST_AsText(geometry) AS geom_text
    WHERE code_commune = '{cog_malakoff}'
")

transactions_malakoff <- dbGetQuery(con, query2)

transactions_malakoff
```

Les transactions extraites sont maintenant chargées en mémoire et on les transforme dans un format `sf`, qui facilite leur manipulation en R via le package `sf`.

```{r}
transactions_malakoff <- 
  sf::st_as_sf(transactions_malakoff, wkt = "geom_text", crs = 2154) |>
  rename(geometry=geom_text)

transactions_malakoff
```

Une fois les données prêtes, on intersecte les points avec le traigle représentant le centre-ville de Malakoff. On utilise de nouveaux les outils du package `sf`.


```{r}
bool_mask <- transactions_malakoff |> 
  sf::st_transform(4326) |> 
  sf::st_intersects(triangle, sparse = FALSE)

in_triangle <- transactions_malakoff[bool_mask,]
out_triangle <- transactions_malakoff[!bool_mask,]
```

Une fois que chaque transaction est identifiée comme étant à l'intérieur ou à l'extérieur du Triangle, le calcul de la médiane des prix est immédiat.

```{r}
median_in <- median(in_triangle$valeur_fonciere)
median_out <- median(out_triangle$valeur_fonciere)

print(glue("Médiane des prix dans le Triangle d'Or de Malakoff : ", median_in))
print(glue("Médiane des prix dans le reste de Malakoff : ", median_out))
```
La médiane des prix est un peu plus élevée dans le Triangle qu'en dehors.


# Partie 3 : Part de ménages pauvres à Malakoff et à Montrouge

Pour finir, on se place dans le cas où : 
- On souhaite extraire des informations d'un fichier volumineux (les données carroyées de l'Insee).
- Mais il n'est pas possible de filtrer les données par des requêtes attributaires (par exemple, il n'est pas possible de faire `code_commune = 92049`).

Ainsi, nous allons : 
- Utiliser les contours géogrpahiques des deux communes
- Filtrer les données par intersections géographiques des carreaux et des communes, à l'aide de `DuckDB`
- Faire les calculs localement après l'extraction des carreaux d'intérêt.


Pour commencer, on décrit les données carroyées comme précédemment :

```{r}
describe_dvf <- dbGetQuery(con, "DESCRIBE SELECT * FROM read_parquet('carreaux.parquet')")
print(describe_dvf)

preview <- dbGetQuery(con, "SELECT * FROM read_parquet('carreaux.parquet') LIMIT 10")
print(preview)
```

Extraction des carreaux intersectant Malakoff : 

- Préparation du contour de Malakoff (reprojection dans le même système que les données carroyées, transformation en Well-Known-Text pour être compatible avec DuckDB)
- Requête sur le fichier `carreaux.parquet` à l'aide de `DuckDB` et de la fonction `ST_Intersects`
- Transformation des carreaux extraits en objet `sf` (uniquement utile pour la cartographie ici).

```{r}
malakoff_2154 <- sf::st_transform(malakoff, 2154)
malakoff_wkt <- sf::st_as_text(sf::st_geometry(malakoff_2154))

geo_query <- glue("
  FROM read_parquet('carreaux.parquet')
  SELECT
      *, ST_AsText(geometry) AS geom_text
  WHERE ST_Intersects(
      geometry,
      ST_GeomFromText('{malakoff_wkt}')
  )
")

carr_malakoff <- dbGetQuery(con, geo_query)

carr_malakoff <-
  carr_malakoff |>
  sf::st_as_sf(wkt = "geom_text", crs = 2154) |>
  select(-geometry) |>
  rename(geometry=geom_text)

mapview(carr_malakoff) + mapview(sf::st_boundary(malakoff)) 
```

On réitère l'opération pour Montrouge : 

```{r}
montrouge_2154 <- sf::st_transform(montrouge, 2154)
montrouge_wkt <- sf::st_as_text(sf::st_geometry(montrouge_2154))

geo_query <- glue("
  FROM read_parquet('carreaux.parquet')
  SELECT
      *, ST_AsText(geometry) AS geom_text
  WHERE ST_Intersects(
      geometry,
      ST_GeomFromText('{montrouge_wkt}')
  )
")

carr_montrouge <- dbGetQuery(con, geo_query)

carr_montrouge <-
  carr_montrouge |>
  sf::st_as_sf(wkt = "geom_text", crs = 2154) |>
  select(-geometry) |>
  rename(geometry=geom_text)

mapview(carr_montrouge) + mapview(sf::st_boundary(montrouge)) 
```

Enfin, on calcule la proportion moyenne de ménages pauvre dans l'ensemble des carreaux extraits : 

```{r}
mean_menpauvres_malakoff <- round(100 * sum(carr_malakoff$men_pauv) / sum(carr_malakoff$men), 2)
mean_menpauvres_montrouge <- round(100 * sum(carr_montrouge$men_pauv) / sum(carr_montrouge$men), 2)

print(glue("Part de ménages pauvres dans les carreaux de Malakoff : ", mean_menpauvres_malakoff))
print(glue("Part de ménages pauvres dans les carreaux de Montrouge : ", mean_menpauvres_montrouge))
```

A noter que cette démarche est améliorable sur plusieurs plans : 
- rationalisation des requêtes,
- pertinence statistique des résultats
- réplicabilité du code


