{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couverture du terrain à partir d'images satellites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation de librairies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/opt/python/bin/pip3\"\u001b[0m, line \u001b[35m7\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/cli/main.py\"\u001b[0m, line \u001b[35m80\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    return \u001b[31mcommand.main\u001b[0m\u001b[1;31m(cmd_args)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/cli/base_command.py\"\u001b[0m, line \u001b[35m158\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    with \u001b[31mself.main_context\u001b[0m\u001b[1;31m()\u001b[0m:\n",
      "         \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m148\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    \u001b[31mnext\u001b[0m\u001b[1;31m(self.gen)\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/cli/command_context.py\"\u001b[0m, line \u001b[35m20\u001b[0m, in \u001b[35mmain_context\u001b[0m\n",
      "    with \u001b[1;31mself._main_context\u001b[0m:\n",
      "         \u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m619\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    raise exc\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m604\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    if \u001b[31mcb\u001b[0m\u001b[1;31m(*exc_details)\u001b[0m:\n",
      "       \u001b[31m~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m148\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    \u001b[31mnext\u001b[0m\u001b[1;31m(self.gen)\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/temp_dir.py\"\u001b[0m, line \u001b[35m40\u001b[0m, in \u001b[35mglobal_tempdir_manager\u001b[0m\n",
      "    with \u001b[31mExitStack\u001b[0m\u001b[1;31m()\u001b[0m as stack:\n",
      "         \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m619\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    raise exc\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m604\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    if \u001b[31mcb\u001b[0m\u001b[1;31m(*exc_details)\u001b[0m:\n",
      "       \u001b[31m~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/temp_dir.py\"\u001b[0m, line \u001b[35m167\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    \u001b[31mself.cleanup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/temp_dir.py\"\u001b[0m, line \u001b[35m210\u001b[0m, in \u001b[35mcleanup\u001b[0m\n",
      "    \u001b[31mrmtree\u001b[0m\u001b[1;31m(self._path, ignore_errors=False)\u001b[0m\n",
      "    \u001b[31m~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/retry.py\"\u001b[0m, line \u001b[35m37\u001b[0m, in \u001b[35mretry_wrapped\u001b[0m\n",
      "    return func(*args, **kwargs)\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/misc.py\"\u001b[0m, line \u001b[35m128\u001b[0m, in \u001b[35mrmtree\u001b[0m\n",
      "    \u001b[31mshutil.rmtree\u001b[0m\u001b[1;31m(dir, onexc=handler)\u001b[0m  # type: ignore\n",
      "    \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/shutil.py\"\u001b[0m, line \u001b[35m763\u001b[0m, in \u001b[35mrmtree\u001b[0m\n",
      "    \u001b[31m_rmtree_safe_fd\u001b[0m\u001b[1;31m(stack, onexc)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/shutil.py\"\u001b[0m, line \u001b[35m696\u001b[0m, in \u001b[35m_rmtree_safe_fd\u001b[0m\n",
      "    \u001b[31mos.unlink\u001b[0m\u001b[1;31m(entry.name, dir_fd=topfd)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/opt/python/bin/pip3\"\u001b[0m, line \u001b[35m7\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/cli/main.py\"\u001b[0m, line \u001b[35m80\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    return \u001b[31mcommand.main\u001b[0m\u001b[1;31m(cmd_args)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/cli/base_command.py\"\u001b[0m, line \u001b[35m158\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    with \u001b[31mself.main_context\u001b[0m\u001b[1;31m()\u001b[0m:\n",
      "         \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m148\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    \u001b[31mnext\u001b[0m\u001b[1;31m(self.gen)\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/cli/command_context.py\"\u001b[0m, line \u001b[35m20\u001b[0m, in \u001b[35mmain_context\u001b[0m\n",
      "    with \u001b[1;31mself._main_context\u001b[0m:\n",
      "         \u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m619\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    raise exc\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m604\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    if \u001b[31mcb\u001b[0m\u001b[1;31m(*exc_details)\u001b[0m:\n",
      "       \u001b[31m~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m148\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    \u001b[31mnext\u001b[0m\u001b[1;31m(self.gen)\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/temp_dir.py\"\u001b[0m, line \u001b[35m40\u001b[0m, in \u001b[35mglobal_tempdir_manager\u001b[0m\n",
      "    with \u001b[31mExitStack\u001b[0m\u001b[1;31m()\u001b[0m as stack:\n",
      "         \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m619\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    raise exc\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/contextlib.py\"\u001b[0m, line \u001b[35m604\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    if \u001b[31mcb\u001b[0m\u001b[1;31m(*exc_details)\u001b[0m:\n",
      "       \u001b[31m~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/temp_dir.py\"\u001b[0m, line \u001b[35m167\u001b[0m, in \u001b[35m__exit__\u001b[0m\n",
      "    \u001b[31mself.cleanup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/temp_dir.py\"\u001b[0m, line \u001b[35m210\u001b[0m, in \u001b[35mcleanup\u001b[0m\n",
      "    \u001b[31mrmtree\u001b[0m\u001b[1;31m(self._path, ignore_errors=False)\u001b[0m\n",
      "    \u001b[31m~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/retry.py\"\u001b[0m, line \u001b[35m37\u001b[0m, in \u001b[35mretry_wrapped\u001b[0m\n",
      "    return func(*args, **kwargs)\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/site-packages/pip/_internal/utils/misc.py\"\u001b[0m, line \u001b[35m128\u001b[0m, in \u001b[35mrmtree\u001b[0m\n",
      "    \u001b[31mshutil.rmtree\u001b[0m\u001b[1;31m(dir, onexc=handler)\u001b[0m  # type: ignore\n",
      "    \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/shutil.py\"\u001b[0m, line \u001b[35m763\u001b[0m, in \u001b[35mrmtree\u001b[0m\n",
      "    \u001b[31m_rmtree_safe_fd\u001b[0m\u001b[1;31m(stack, onexc)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/python/lib/python3.13/shutil.py\"\u001b[0m, line \u001b[35m696\u001b[0m, in \u001b[35m_rmtree_safe_fd\u001b[0m\n",
      "    \u001b[31mos.unlink\u001b[0m\u001b[1;31m(entry.name, dir_fd=topfd)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -q -q tifffile\n",
    "!pip install tqdm matplotlib\n",
    "!pip3 install -q -q -q torch\n",
    "!pip3 install -q -q -q torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des librairies et modules utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import os\n",
    "import s3fs\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from tifffile import TiffFile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivant indique si un ou plusieurs GPUs (Graphics Processing Units) sont disponibles et peuvent être utilisés pour faire les calculs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): device= torch.device(\"cuda:0\" )\n",
    "else: device = \"cpu\"\n",
    "\n",
    "print(\"Using {} device\".format(device))\n",
    "if torch.cuda.is_available():\n",
    "    print(\"nom du GPU :\", torch.cuda.get_device_name(device=None))\n",
    "    print(\"GPU initialisé : \", torch.cuda.is_initialized())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on veut réaliser une segmentation d'images satellites. Ce problème est plus complexe que celui de la classificaton d'image dans la mesure où l'on souhaite attribuer à chaque pixel d'une image satellite donnée une classe, en l'occurrence un type de sol (eau, bâtiment, surface cultivée, etc..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 7001M  100 7001M    0     0  59.8M      0  0:01:57  0:01:57 --:--:-- 77.2M 38.8M      0  0:03:00  0:00:16  0:02:44 66.5M\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m      7\u001b[39m     get_ipython().system(\u001b[33m\"\u001b[39m\u001b[33mcurl \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://minio.lab.sspcloud.fr/projet-funathon/2022/diffusion/Sujet9_deep_learning_donnees_satellites/additional_files_earthcube_emu4zqr.zip\u001b[39m\u001b[33m'\u001b[39m\u001b[33m --output \u001b[39m\u001b[33m'\u001b[39m\u001b[33madditional_files_earthcube_emu4zqr.zip\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43munpack_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43madditional_files_earthcube_emu4zqr.zip\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mextract_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msatellite\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m os.remove(\u001b[33m'\u001b[39m\u001b[33madditional_files_earthcube_emu4zqr.zip\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/shutil.py:1360\u001b[39m, in \u001b[36munpack_archive\u001b[39m\u001b[34m(filename, extract_dir, format, filter)\u001b[39m\n\u001b[32m   1358\u001b[39m func = _UNPACK_FORMATS[\u001b[38;5;28mformat\u001b[39m][\u001b[32m1\u001b[39m]\n\u001b[32m   1359\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(_UNPACK_FORMATS[\u001b[38;5;28mformat\u001b[39m][\u001b[32m2\u001b[39m]) | filter_kwargs\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/shutil.py:1267\u001b[39m, in \u001b[36m_unpack_zipfile\u001b[39m\u001b[34m(filename, extract_dir)\u001b[39m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name.endswith(\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1264\u001b[39m             \u001b[38;5;66;03m# file\u001b[39;00m\n\u001b[32m   1265\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mzip\u001b[39m.open(name, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[32m   1266\u001b[39m                     \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[32m-> \u001b[39m\u001b[32m1267\u001b[39m                 \u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1268\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1269\u001b[39m     \u001b[38;5;28mzip\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/shutil.py:204\u001b[39m, in \u001b[36mcopyfileobj\u001b[39m\u001b[34m(fsrc, fdst, length)\u001b[39m\n\u001b[32m    202\u001b[39m fdst_write = fdst.write\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m buf := fsrc_read(length):\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': 'https://minio.lab.sspcloud.fr'})\n",
    "if not os.path.exists('satellite'):\n",
    "    os.mkdir('satellite')\n",
    "try:\n",
    "    fs.get('projet-funathon/2022/diffusion/Sujet9_deep_learning_donnees_satellites/additional_files_earthcube_emu4zqr.zip', 'additional_files_earthcube_emu4zqr.zip')\n",
    "except:\n",
    "    !curl 'https://minio.lab.sspcloud.fr/projet-funathon/2022/diffusion/Sujet9_deep_learning_donnees_satellites/additional_files_earthcube_emu4zqr.zip' --output 'additional_files_earthcube_emu4zqr.zip'\n",
    "shutil.unpack_archive('additional_files_earthcube_emu4zqr.zip',\n",
    "                      extract_dir='satellite')\n",
    "os.remove('additional_files_earthcube_emu4zqr.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dans l'exemple précédent on récupère l'ensemble des chemins de fichiers correspondants aux images satellites utilisées ainsi que l'ensemble des annotations associées.\n",
    "\n",
    "Notez qu'ici chaque annotation n'est plus une unique valeur numérique (0, 1) mais un tableau de valeurs de même dimension que l'image. Pour chaque pixel, la valeur correspond au type d'occupation du sol (de 1 à 9). On appelle ces annotations particulières des **masques de segmentation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les images utlisées ici ont en plus des 3 canaux habituels (R, G, B), un quatrième canal correspondant à la mesure d'une bande infra-rouge. En pratique beaucoup d'autres bandes spectrales sont disponibles pour les images satellites. Cet exercice se restreint seulement à 4 bandes (R, G, B, infra-rouge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_STR = 'satellite/dataset'\n",
    "DATA_FOLDER = Path(DATA_FOLDER_STR).expanduser()\n",
    "DATASET_FOLDER = DATA_FOLDER\n",
    "\n",
    "# Get all train images and masks\n",
    "train_images_paths = sorted(list(DATASET_FOLDER.glob('train/images/*.tif')))\n",
    "train_masks_paths = sorted(list(DATASET_FOLDER.glob('train/masks/*.tif')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ici la classe `CustomDataset` qui nous permettra d'accéder aux images satellites et aux masques, comme dans l'exemple précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        with TiffFile(self.mask_paths[idx]) as tif :\n",
    "            mask = tif.asarray()\n",
    "        with TiffFile(self.image_paths[idx]) as tif :\n",
    "            image = np.array(tif.asarray())\n",
    "\n",
    "        t_mask = torch.tensor(mask, dtype=torch.long)\n",
    "        image = torch.tensor(np.array(image, dtype=float), dtype=torch.float)\n",
    "        identifier = str(self.mask_paths[idx])\n",
    "        return {\"image\": image, \"masque\" : t_mask, \"id\" : identifier}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe `LandCoverData` contient des informations en dur sur notre jeu d'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandCoverData():\n",
    "    IMG_SIZE = 256\n",
    "    N_CHANNELS = 4\n",
    "    N_CLASSES = 10\n",
    "    MEAN_CHANNEL = [339.42029674, 570.98497474,  539.11161384, 2634.49868179]\n",
    "    STD_CHANNEL = [339.79895785, 404.86935149,  549.41877854, 1071.38939764]\n",
    "    COUNT_CLASS =  np.array([0, 20643, 60971025, 404760981, 277012377, 96473046, 333407133, 9775295, 1071, 29404605])\n",
    "    WEIGHT_CLASS = np.array(\n",
    "        [0.0000e+00, 0.0000e+00, 1.6401e-08, 2.4706e-09, 3.6099e-09, 1.0366e-08,\n",
    "         2.9993e-09, 1.0230e-07, 9.3371e-04, 3.4008e-08]\n",
    "    ) * np.sum(COUNT_CLASS)\n",
    "    CLASSES = [\n",
    "    'no_data',\n",
    "    'clouds',\n",
    "    'artificial',\n",
    "    'cultivated',\n",
    "    'broadleaf',\n",
    "    'coniferous',\n",
    "    'herbaceous',\n",
    "    'natural',\n",
    "    'snow',\n",
    "    'water']\n",
    "\n",
    "    TRAINSET_SIZE = 18491\n",
    "    TESTSET_SIZE = 5043\n",
    "\n",
    "    CLASSES_COLORPALETTE = {\n",
    "    0: [0,0,0],\n",
    "    1: [255,25,236],\n",
    "    2: [215,25,28],\n",
    "    3: [211,154,92],\n",
    "    4: [33,115,55],\n",
    "    5: [21,75,35],\n",
    "    6: [118,209,93],\n",
    "    7: [130,130,130],\n",
    "    8: [255,255,255],\n",
    "    9: [43,61,255]\n",
    "    }\n",
    "    CLASSES_COLORPALETTE = {c: np.asarray(color) for (c, color) in CLASSES_COLORPALETTE.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test de la classe `CustomDataset`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(train_images_paths, train_masks_paths)\n",
    "\n",
    "# Construction d'un itérateur\n",
    "iterateur = iter(dataset)\n",
    "\n",
    "# Récupération du premier jeu (image,masque) du dataset\n",
    "element_dataset = next(iterateur)\n",
    "image = element_dataset[\"image\"]\n",
    "masque = element_dataset[\"masque\"]\n",
    "\n",
    "print(image.shape)\n",
    "print(masque.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le masque a bien les mêmes dimensions que l'image associée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage d'une image et d'un masque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions suivantes permettent d'afficher une image et un masque respectivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, display_min=50, display_max=400, ax=None):\n",
    "    \"\"\"\n",
    "    Show an image.\n",
    "\n",
    "    Args:\n",
    "        image (numpay.array[uint16]): the image. If the image is 16-bit,\n",
    "        apply bytescaling to convert to 8-bit.\n",
    "    \"\"\"\n",
    "    if image.dtype == np.uint16:\n",
    "        iscale = display_max - display_min\n",
    "        scale = 255 / iscale\n",
    "        byte_im = (image) * scale\n",
    "        byte_im = (byte_im.clip(0, 255) + 0.5).astype(np.uint8)\n",
    "        image = byte_im\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_mask(mask, classes_colorpalette, classes=None, add_legend=True, ax=None):\n",
    "    \"\"\"\n",
    "    Show a a semantic segmentation mask.\n",
    "\n",
    "    Args:\n",
    "       mask (numpy.array[uint8]): the mask in 8-bit\n",
    "       classes_colorpalette (dict[int, tuple]): dict mapping class index to an RGB color in [0, 1]\n",
    "       classes (list[str], optional): list of class labels\n",
    "       add_legend\n",
    "    \"\"\"\n",
    "    show_mask = np.empty((*mask.shape, 3))\n",
    "    for c, color in classes_colorpalette.items():\n",
    "        show_mask[mask == c, :] = color\n",
    "    show_mask = show_mask.astype(np.uint8)\n",
    "\n",
    "    plt.imshow(show_mask)\n",
    "    handles = []\n",
    "    for c, color in LandCoverData.CLASSES_COLORPALETTE.items():\n",
    "        handles.append(mpatches.Patch(color=color/255, label=LandCoverData.CLASSES[c]))\n",
    "    plt.legend(handles=handles)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image :\")\n",
    "show_image(np.array(image).astype(np.uint16),display_min = 0, display_max = 2200)\n",
    "\n",
    "print(\"Masque :\")\n",
    "show_mask(np.array(masque),LandCoverData.CLASSES_COLORPALETTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dictionnaire suivant contient tous les paramètres nécessaires pour l'entraînement du futur modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'monitoring': True,\n",
    "    'freq monitoring': 50,\n",
    "    'n_epoch': 80,\n",
    "    'train_size': 15000,\n",
    "    'batch_size':  28,\n",
    "    'optimizer': \"SGD\",\n",
    "    'lr': 0.003,\n",
    "    'momentum': 0.9,\n",
    "    'model type': \"segmentation mask\",\n",
    "    'init_features': 16,\n",
    "    'validation_n_batch': 2000,\n",
    "    'descriptif': \"Entrainement avec un Unet pour segmentation + cross entropy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ici le `DataLoader` qui va nous permettre de charger les images et leur labels par batchs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  config['batch_size']\n",
    "all_dataset = CustomDataset(train_images_paths,train_masks_paths)\n",
    "all_loader = DataLoader(all_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "train_size = config['train_size']\n",
    "val_size = len(all_dataset.mask_paths) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(all_dataset, [train_size,val_size], generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition d'un modèle U-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dans l'exemple sur la classification, on va utiliser un réseau de neurones convolutifs pour prédires des masques de segmentation. On définit un modèle convolutif bien plus complexe que le précédent. Ce type de modèles est très utilisé dans la littérature pour répondre au problème de segmentation sémantique.\n",
    "\n",
    "Ce U-net est composé : \n",
    "- d'une phase descendante qui extrait des caractéristiques de l'image \n",
    "- d'une phase descendante qui à partir des caractéristiques extraites réalisera la classification de l'image en entrée pixel par pixel\n",
    "\n",
    "Pour plus d'information sur le U-net, voir [ce lien](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwj0746Sva34AhWSBhoKHVtvDrIQFnoECAoQAQ&url=https%3A%2F%2Farxiv.org%2Fabs%2F1505.04597&usg=AOvVaw2VMp5nhjei6r-QgaG3XTpUhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwj0746Sva34AhWSBhoKHVtvDrIQFnoECAoQAQ&url=https%3A%2F%2Farxiv.org%2Fabs%2F1505.04597&usg=AOvVaw2VMp5nhjei6r-QgaG3XTpU).\n",
    "\n",
    "La construction est détaillée ci-dessous. Le paramètre `init_features` permettra de jouer sur la taille de réseau que l'on souhaite obtenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, init_features,in_channels=4, out_channels=10):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 4, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bottleneck = UNet._block(features * 4, features * 8, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 4) * 2, features * 4, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 4, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool2(enc2))\n",
    "\n",
    "        dec2 = self.upconv2(bottleneck)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (name + \"conv1\", nn.Conv2d(in_channels=in_channels, out_channels=features, kernel_size=3, padding=1, bias=False,),),\n",
    "                    (name + \"Batchnorm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (name + \"conv2\",nn.Conv2d(in_channels=features, out_channels=features, kernel_size=3, padding=1, bias=False,),),\n",
    "                    (name + \"Batchnorm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour information, la cellule ci-dessous présente une méthode de construction du U-net\n",
    "où on récupère ici une structure de modèle sur https://github.com/mateuszbuda/brain-segmentation-pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDl(nn.Module):\n",
    "\n",
    "    def __init__(self,init_features):\n",
    "        super().__init__()\n",
    "        self.unet = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "        in_channels= 4, out_channels=10, init_features= init_features, pretrained=False, verbose = False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.unet(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comptons le nombre de paramètres du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp = 0\n",
    "    for p in list(model.parameters()):\n",
    "        nn = 1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(config['init_features'])\n",
    "get_n_params(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque :** Près d'un demi-million de paramètres pour ce réseau !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la même façon que précedemment, on entraîne notre modèle. La logique reste la même : on actualise les paramètres du modèle, batch après batch en calculant une erreur commise par le modèle sur le batch et son gradient.\n",
    "\n",
    "L'erreur commise pour une image est la moyenne des erreurs commises sur les labels de chacun de ses pixels (entropie croisée)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(config['init_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque :** Même avec un GPU l'entraînement d'un modèle aussi gros peut  prendre une quinzaine d'heures. C'est pourquoi nous vous invitons à lancer la cellule ci-dessous pour constater que l'entraînement se lance bien. Puis vous pouvez arrêter l'entraînement et passer à la partie suivante où on charge des modèles qui ont été pré-entrainés par nos soins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "net = net.to(device)\n",
    "entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(config['n_epoch']):\n",
    "        net = net.to(device)\n",
    "        running_loss = 0.0\n",
    "        t = tqdm(train_loader, desc=\"epoch %i\" % (epoch+1),position = 0, leave=True)\n",
    "        epoch_loop = enumerate(t)\n",
    "\n",
    "        for i, data in epoch_loop:\n",
    "            taille_batch = data['image'].shape[0]\n",
    "            images = data['image'].permute(0, 3, 1, 2)\n",
    "            masques  =  data['masque']\n",
    "            images, masques = images.to(device), masques.long().to(device)\n",
    "            y_hat = net(images)\n",
    "            optimizer.zero_grad()\n",
    "            loss = entropy(y_hat,masques)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del images, masques, y_hat # libéreer un peu d'espace\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if (i+1) % config['freq monitoring'] == 0:\n",
    "                t.set_description(\"epoch %i, 'mean loss: %.6f'\" % (epoch+1, run