---
title: "Application 2: classification automatique de textes"
echo: false
output-dir: _site
filters:
- custom-callout
format:
   html:
     df-print: paged
execute:
  daemon: false
---

Cette application illustrera certains apports des outils du
NLP pour la codification automatique des d√©clarations d'activit√©
dans la nomenclature des activit√©s fran√ßaises.
Vous pourrez r√©aliser ce TP dans un service pr√©configur√© du `SSP Cloud` en cliquant sur le lien ci-dessous :

<a href="https://datalab.sspcloud.fr/launcher/ide/vscode-pytorch?name=vscode-pytorch-nouvellessouces&version=2.4.5&s3=region-79669f20&init.personalInit=¬´https%3A%2F%2Fraw.githubusercontent.com%2FInseeFrLab%2Fcours-nouvelles-donnees-site%2Frefs%2Fheads%2Fmain%2Fapplications%2Fapp2-init.sh¬ª&autoLaunch=true" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/SSPcloud-Ouvrir sur le sspcloud (VSCode)-informational&amp;color=yellow?logo=Python" alt="Onyxia"></a>


Ce tutoriel n'a pas vocation √† introduire aux principaux concepts du NLP (tokenisation, sac de mot, _embedding_, etc.) mais √† √™tre une introduction pratique √† la th√©matique de la classification textuelle. Pour d√©couvrir les concepts centraux du NLP, se r√©f√©rer au cours de [`Python` pour la _data science_](https://pythonds.linogaliana.fr/content/NLP/) de l'ENSAE.


## Objectifs

Ce tutoriel se propose d'illustrer la probl√©matique de la classification automatique en mobilisant un algorithme d'apprentissage supervis√© de type `FastText`, √† partir des donn√©es issues des d√©clarations Sirene.

L'id√©e de ce tutoriel est de classer des d√©clarations d'entreprises dans une nomenclature g√©n√©rique des activit√©s productives. Celle-ci permet de produire de nombreuses statistiques √©conomiques sectorielles sur le tissu productif fran√ßais.

L'Insee ayant vocation √† produire des statistiques agr√©g√©es sur de nombreuses questions, cette approche constitue l'un des principaux cas d'application du NLP pour l'Institut dans des domaines aussi divers que la classification dans une nomenclature d'activit√©s (NAF), une nomenclature de professions (PCS), de produits (COICOP), de lieux g√©ographiques, etc.

Comment passe-t-on d'une d√©claration en langage naturel, qui fait sens pour un entrepreneur, √† une repr√©sentation plus g√©n√©rique, et forc√©ment plus simpliste, de l'activit√© d'une entreprise, qui fait sens √† une institution statistique et esp√©rons, pour le d√©bat public ? Gr√¢ce √† des algorithmes de classement _ad hoc_ qui permettent d'extraire une information √† partir de libell√©s textuels. Historiquement l'Insee utilisait des r√®gles d√©terministes de classement √† partir d'un algorithme nomm√© [Sicore](https://www.insee.fr/fr/information/4497076?sommaire=4497095), une IA symbolique qui classait √† partir de r√®gles m√©tiers pr√©configur√©e.

Avec l'av√®nement du _machine learning_, la possibilit√© d'entra√Æner un algorithme apprenant par induction plut√¥t que de mani√®re d√©ductive, est apparue √™tre une voie d'investissement int√©ressante pour l'Insee. L'objet de ce TD est d'illustrer la d√©marche adopt√©e avec cette approche √† partir d'un mod√®le un peu plus simple que celui mis en oeuvre √† l'Insee mais reprenant les principales caract√©ristiques de celui-ci.

Voici un sch√©ma simplifi√© pour comprendre l'architecture de notre mod√®le (tr√®s proche de Fasttext) : 

![](images/fasttext_schema.png){.lightbox}

## Environnement de travail

Le services VSCode pr√©configur√© contient :

- les donn√©es dans un dossier "data"
- un module de preprocessing
- un script `script_tp.py` vierge o√π √©crire votre code (la puce `# %%` permet une utilisation int√©ractive √† l'instar des notebooks Jupyter).

![](vscode.png)

## Exploration du jeu de donn√©es

Le code pour lire les donn√©es est directement fourni :

```{python}
#| echo: true
#| label: download-data

import os
import pandas as pd

# Import NAF classification
naf = pd.read_excel("data/naf.xls", skiprows = 2)

# Import training data
train = pd.read_parquet("data/data.parquet")

# Merge classification info
naf['Code'] = naf['Code'].str.replace(".","")
train = train.merge(naf, left_on = "nace", right_on = "Code")
train.head(5)

```


Le premier exercice a vocation √† illustrer la mani√®re classique ¬´ d'entrer ¬ª dans un corpus de donn√©es textuelles.

La d√©marche n'est pas particuli√®rement originale mais permet d'illustrer les enjeux du nettoyage de texte.

::: {.exercice}
## Exercice 1

0. Lancer le code ci-dessous pour pr√©parer votre environnement de travail :

```{.python}
# Charge la biblioth√®que spaCy pour le traitement du langage naturel (NLP)
import spacy

# T√©l√©charge le mod√®le fran√ßais pour spaCy (n√©cessaire pour l'analyse morphosyntaxique en fran√ßais)
os.system("python -m spacy download fr_core_news_sm")

# Charge la biblioth√®que NLTK pour le traitement du texte
import nltk

# T√©l√©charge le tokeniseur "punkt_tab" de NLTK (pour la segmentation en phrases/tokens)
nltk.download('punkt_tab')

# T√©l√©charge la liste des stopwords fran√ßais/anglais de NLTK (mots vides comme "le", "la", "the", etc.)
nltk.download('stopwords')

```

1. Cr√©er une fonction `filter_train_data` qui filtre les lignes du df dont le libell√© d'activit√© __contient__ un pattern (mot) donn√©.
Cette fonction aussi doit afficher (print) le nombre de lignes concern√©es.
Tester avec _"data science"_ et _"boulanger"_.

2. Faire une fonction `graph_wordcloud` pour afficher le _wordcloud_ de notre corpus dans son ensemble et de certaines
cat√©gories de la nomenclature pour comprendre la nature de notre corpus.


<details>
<summary>
Aide
</summary>

```{.python}
import matplotlib.pyplot as plt
from wordcloud import WordCloud

all_text = ["boulanger", "chauffer", "bus"]

wordcloud = WordCloud(
    width=800,
    height=500,
    random_state=21,
    max_words=2000,
    background_color="white",
    colormap='Set2'
).generate(all_text)

```

</details>




3. Retirer les stopwords √† partir de la liste des mots disponibles dans `SpaCy`.

<details>
<summary>
Aide
</summary>

```{.python}
import spacy
from nltk.tokenize import word_tokenize

nlp = spacy.load("fr_core_news_sm")
stop_words = nlp.Defaults.stop_words
stop_words = set(stop_words)

# Function to remove stopwords
def remove_stopwords(text):
    word_tokens = word_tokenize(text)
    filtered_text = ...
    return ' '.join(filtered_text)

def remove_single_letters(text):
    word_tokens = word_tokenize(text)
    filtered_text = ...
    return ' '.join(filtered_text)

# Apply the function to the 'text' column
train['text_clean'] = (train['text']
    .apply(remove_stopwords)
    .apply(remove_single_letters)
)
```

</details>


4. Refaire quelques uns des nuages de mots et √©tudier la diff√©rence avant nettoyage.


:::

Dans une d√©marche exploratoire, le plus simple est de commencer par compter les mots de mani√®re ind√©pendante (approche sac de mot).
Par exemple, de mani√®re naturelle, nous avons beaucoup plus de d√©clarations li√©es √† la boulangerie que li√©es √† la _data science_:

```{python}
#| label: filter_train_data
train_data=train.copy()

def filter_train_data(train_data, sequence):
    sequence_capitalized = sequence.upper()
    mask = train_data['text'].str.contains(sequence_capitalized)
    nb_occurrence = mask.astype(int).sum()
    print(
        f"Nombre d'occurrences de la s√©quence '{sequence}': {nb_occurrence}"
    )
    return train_data.loc[mask]
```

```{python}
#| label: use-filter_train_data
#| echo: true
filter_train_data(train, "data science").head(5)
```
```{python}
#| label: use-filter_train_data2
#| echo: true
filter_train_data(train, "boulanger").head(5)
```

```{python}
#| label: def-graph_wordcloud
import matplotlib.pyplot as plt
from wordcloud import WordCloud

def graph_wordcloud(train_data, text_var="text", naf=None):
    if naf is not None:
        train_data = train_data.loc[train_data['nace'] == naf]

    txt = train_data[text_var]
    all_text = ' '.join([text for text in txt])
    wordcloud = WordCloud(
        width=800,
        height=500,
        random_state=21,
        max_words=2000,
        background_color="white",
        colormap='Set2'
    ).generate(all_text)
    return wordcloud
```

Les _wordclouds_ peuvent servir √† rapidement visualiser la structure d'un corpus.
On voit ici que notre corpus est tr√®s bruit√© car nous n'avons pas nettoy√© celui-ci:

```{python}
#| label: use-graph_wordcloud
wordcloud_corpus = graph_wordcloud(train.sample(10000))
plt.imshow(wordcloud_corpus, interpolation="bilinear")
```

Pour commencer √† se faire une id√©e sur les sp√©cificit√©s des cat√©gories, on peut repr√©senter le corpus de certaines d'entre elles ?
Arrivez-vous √† inf√©rer la cat√©gorie de la NAF en question ? Si oui, vous utilisez sans doute des heuristiques
proches de celles que nous allons mettre en oeuvre dans notre algorithme de classification.

```{python}
#| label: use-graph_wordcloud2
wordcloud_corpus = graph_wordcloud(train, naf = "1071C")
plt.imshow(wordcloud_corpus, interpolation="bilinear")
```

```{python}
#| label: use-graph_wordcloud3
wordcloud_corpus = graph_wordcloud(train, naf = "4942Z")
plt.imshow(wordcloud_corpus, interpolation="bilinear")
```

N√©anmoins, √† ce stade, les donn√©es sont encore tr√®s bruit√©es.
La premi√®re √©tape classique est de retirer les _stop words_ et √©ventuellement des termes sp√©cifiques √† notre corpus.
Par exemple, pour des donn√©es de caisse, on retirera les bruits, les abr√©viations, etc. qui peuvent bruiter notre corpus.

```{python}
#| label: data-cleaning
from nltk.tokenize import word_tokenize
import spacy

nlp = spacy.load("fr_core_news_sm")
stop_words = nlp.Defaults.stop_words
stop_words = set(stop_words)

# Function to remove stopwords
def remove_stopwords(text):
    word_tokens = word_tokenize(text)
    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]
    return ' '.join(filtered_text)

def remove_single_letters(text):
    word_tokens = word_tokenize(text)
    filtered_text = [word for word in word_tokens if len(word) > 1]
    return ' '.join(filtered_text)

# Apply the function to the 'text' column
train['text_clean'] = (train['text']
    .apply(remove_stopwords)
    .apply(remove_single_letters)
)
```

Voici le wordcloud de notre corpus tout entier une fois cette premi√®re √©tape de nettoyage achev√©e :

```{python}
#| label: use-graph_wordcloud4
wordcloud_corpus_cleaned = graph_wordcloud(train.sample(10000), "text_clean")
plt.imshow(wordcloud_corpus_cleaned, interpolation="bilinear")
```




## Premier algorithme d'apprentissage supervis√©

Nous avons nettoy√© nos donn√©es. Cela devrait am√©liorer la pertinence de nos mod√®les en r√©duisant le ratio signal/bruit.
Nous allons g√©n√©raliser notre nettoyage de texte en appliquant un peu plus d'√©tapes que pr√©c√©demment. Nous allons
notamment _raciniser_ nos mots.

Pour cela, il suffit de charger le module `processor.py` mis √† disposition dans votre environnement de travail.
Le code de nettoyage est directement fourni:

```{python}
#| label: data-processessing
#| echo: true

from processor import Preprocessor
preprocessor = Preprocessor()

# Preprocess data before training and testing
TEXT_FEATURE = "text"
Y = "nace"

df = train.copy()

df = preprocessor.clean_text(df, TEXT_FEATURE).drop('text_clean', axis = "columns")
df.head(2)
```

Pour d√©velopper votre code, utilisez un √©chantillon des donn√©es pour √©viter les temps de calculs trop long au d√©but.

R√©cup√©rons les features et les labels.

```{python}
#| label: get-features
#| echo: true

df = df.dropna(subset = [Y, TEXT_FEATURE])
X = df[TEXT_FEATURE].values
y = df[Y].values
```



::: {.exercice}

1. Encoder les labels et d√©couper les donn√©es en _train_, _val_ et _test_.

<details>
<summary>
Aide
</summary>

```{.python}
# Pour l'encoding :
from sklearn.preprocessing import LabelEncoder

# Pour le split :
from sklearn.model_selection import train_test_split

```
</details>

Nous allons utiliser `torchTextClassifiers (ttc)` pour entra√Æner notre mod√®le.
`ttc` est un framework de codification automatique, construit sur `torch` et qui permet de d'entra√Æner des mod√®les de codification automatique.
`ttc` va ici nous permettre d'entra√Æner un mod√®le de type `Fasttext`, mais sans passer par la vieille librairie archiv√©e par Meta.
√Ä noter que `ttc` est une librairie _opensource_, d√©velopp√©e et maintenue par l'Insee (unit√© SSPLab).

La premi√®re √©tape consiste √† instancier un tokenizer.
Nous allons utiliser ici le tokenizer basique de la m√©thodologie `Fasttext` (d√©coupage en mots, ngrams de mots et ngrams de caract√®res).

2. Instancier un tokenizer `NGramTokenizer` (essayer √† partir de la documentation de `torchTextClassifiers` - ou en reprenant le code ci-dessous pour les moins courageux)

<details>
<summary>
Aide
</summary>

```{.python}
from torchTextClassifiers.tokenizers.ngram import NGramTokenizer

tokenizer = NGramTokenizer(
    min_count=2, # On consid√®re un mot s'il est trouv√© au moins 2 fois dans le corpus
    min_n=2,
    max_n=4, # On fait des 2grams, 3grams et 4grams de caract√®res
    len_word_ngrams=2, # On fait des 2grams de mots
    num_tokens=10000, # Nombre max de tokens consid√©r√©s dans le vocable
    training_text=X, # Jeu d'entra√Ænement du tokenizer
)
```
</details>



3. Etudiez le code dans l'aide ci-dessous et lancez-le. Malheureusement, l'entra√Ænement d'un bon mod√®le prend du temps et de la ressource (GPU) : ici, nous vous donnons le code pour faire toutes les √©tapes vous-m√™me mais, au lieu de faire l'entra√Ænement (code en commentaire), nous vous proposons de t√©l√©charger un mod√®le d√©j√† entra√Æn√© par nos soins (avec les m√™mes donn√©es et les m√™mes configurations que celles du TP).


<details>
<summary>
Aide
</summary>

```{.python}

# Set model configs ---------------

from torchTextClassifiers import ModelConfig
import numpy as np

# Embedding dimension
embedding_dim = 64

# Count number of unique labels
unique_values, counts = np.unique(y, return_counts=True)
num_unique = len(unique_values)

model_config = ModelConfig(
    embedding_dim=embedding_dim,
    num_classes=num_unique
)

# Instanciate a ttc model (nammed "classifier") ---------------

from torchTextClassifiers import torchTextClassifiers

classifier = torchTextClassifiers(
    tokenizer=tokenizer,
    model_config=model_config
)

# Set the training configs ---------------

from torchTextClassifiers import TrainingConfig

# Training params (torch style)
training_config = TrainingConfig(
    num_epochs=30,
    batch_size=8,
    lr=1e-3,
    patience_early_stopping=7,
    num_workers=0,
    trainer_params={'deterministic': True}
)

# Training (too long) !

# classifier.train(
#     X_train,
#     y_train,
#     training_config,
#     X_val,
#     y_val,
#     verbose=True
# )

# Download a pre-trained instead to make it faster :

# Download the model
base_url = "https://minio.lab.sspcloud.fr/projet-formation/nouvelles-sources/model_ape"
files = ["metadata.pkl", "model_checkpoint.ckpt", "tokenizer.pkl"]

import subprocess

for file in files:
    subprocess.run([
        "curl",
        f"{base_url}/{file}",
        "--output", f"model_ape/{file}",
        "--silent",
        "--fail",  # Fail on HTTP errors
        "--location"  # Follow redirects
    ], check=True)


# Load it
classifier = torchTextClassifiers.load("model_ape")

```
</details>

4. Calculer l'accuracy du mod√®le.

5. Tester le mod√®le sur quelques libell√©s de professions :

```{.python}
searched_professions = np.array(["Conseil datascience", "Conc√©sion dans l'automobile", "Concession automobile", "peintre"])
```

:::


```{python}
#| label: label-encoding
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)  # Convertit ["cat", "dog"] ‚Üí [0, 1]
```


```{python}
#| label: split-data

# Premi√®re division : train (80 %) + test (20%)
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y_encoded,
    test_size=0.2,
    random_state=0,
    shuffle=True,
)
# Deuxi√®me division pour aboutir √† : train (60 % = 80% * 75%) + val =  (60 % = 80% * 25%) + test (20%)

X_train, X_val, y_train, y_val = train_test_split(
    X_train,
    y_train,
    test_size=0.25,
    random_state=0,
    shuffle=True,
)
```


```{python}
#| label: useless-chunk

# from torchTextClassifiers.tokenizers.ngram import NGramTokenizer

# tokenizer = NGramTokenizer(
#     min_count=2, # On consid√®re un mot s'il est trouv√© au moins 2 fois dans le corpus
#     min_n=2,
#     max_n=4, # On fait des 2grams, 3grams et 4grams de caract√®res
#     len_word_ngrams=2, # On fait des 2grams de mots
#     num_tokens=10000, # Nombre max de tokens consid√©r√©s dans le vocable
#     training_text=X, # Jeu d'entra√Ænement du tokenizer
# )

# # Set model configs ---------------

# from torchTextClassifiers import ModelConfig
# import numpy as np

# # Embedding dimension
# embedding_dim = 64

# # Count number of unique labels
# unique_values, counts = np.unique(y, return_counts=True)
# num_unique = len(unique_values)

# model_config = ModelConfig(
#     embedding_dim=embedding_dim,
#     num_classes=num_unique
# )

# # Instanciate a ttc model (nammed "classifier") ---------------

# from torchTextClassifiers import torchTextClassifiers

# classifier = torchTextClassifiers(
#     tokenizer=tokenizer,
#     model_config=model_config
# )

# # Set the training configs ---------------

# from torchTextClassifiers import TrainingConfig

# # Training params (torch style)
# training_config = TrainingConfig(
#     num_epochs=30,
#     batch_size=8,
#     lr=1e-3,
#     patience_early_stopping=7,
#     num_workers=0,
#     trainer_params={'deterministic': True}
# )

```

Chargement du mod√®le :

```{python}
#| label: load-model
from torchTextClassifiers import torchTextClassifiers as ttc
classifier = ttc.load("model_ape")
```

Evaluation du mod√®le :

```{python }
#| label: get-accuracy

# Force single-threaded execution (for gh actions)
import torch.multiprocessing as mp
mp.set_start_method("spawn", force=True)
import torch
import os
torch.set_num_threads(1)
torch.set_num_interop_threads(1)
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"

import numpy as np
n = X_test.shape[0]
sample_size = min(1000, n)

rng = np.random.default_rng(seed=42)
idx = rng.choice(n, size=sample_size, replace=False)

X_sample = X_test[idx]
y_sample = y_test[idx]

# Inference on testset
result = classifier.predict(X_sample)

```

```{python }
#| label: get-accuracy2
predictions = result["prediction"].squeeze().numpy()
```

```{python }
#| label: get-accuracy3

# Step 8: Evaluate
accuracy = (predictions == y_sample).mean()
print(f"Test accuracy: {accuracy:.3f}")

```

Testons le mod√®le sur quelques libell√©s d'activit√© :

```{python}
#| label: test-inference
import numpy as np

searched_professions = np.array(["Conseil datascience", "Conc√©sion dans l'automobile", "Concession automobile", "peintre"])
preds = classifier.predict(searched_professions)

for profession, prediction, confidence in zip(searched_professions, preds["prediction"], preds["confidence"]):
    # Affichage de la profession recherch√©e
    print(f"\nüîç Profession recherch√©e : {profession}")

    # Conversion s√©curis√©e de la pr√©diction (compatible PyTorch/NumPy)
    pred_code = prediction.cpu().numpy()
    pred_labels = le.inverse_transform(pred_code)

    # R√©cup√©ration des libell√©s NAF correspondants
    matching_labels = naf.loc[naf["Code"].isin(pred_labels), "Libell√©"].tolist()

    # Affichage des r√©sultats
    print(f"üè∑Ô∏è Profession(s) trouv√©e(s) : {', '.join(matching_labels)}")
    print(f"üìä Confiance : {confidence.item() if hasattr(confidence, 'item') else confidence:.2f}")


```



## Pour aller plus loin, introduction au MLOps

On utilise dans cette application un mod√®le de Machine
Learning (ML) pour pr√©dire l'activit√© des entreprises √†
partir de texte descriptifs. Les m√©thodes de
ML sont quasiment indispensables pour traiter du texte,
mais utiliser des mod√®les de ML pour servir des cas d'usage
r√©els demande de respecter un certain nombre de bonnes pratiques
pour que tout se passe convenablement, en particulier:

- Tracking propre des exp√©rimentations
- Versioning des mod√®les, en m√™me temps que des donn√©es et du code correspondants
- Mise √† disposition efficace du mod√®le aux utilisateurs
- Monitoring de l'activit√© du mod√®le servi
- R√©entra√Ænement du mod√®le

Une introduction √† ces bonnes pratiques, auxquelles on fait
r√©guli√®rement r√©f√©rence √† travers le terme MLOps, est donn√© dans
[cette formation](https://inseefrlab.github.io/formation-mlops/slides/fr/index.html#/title-slide)
([d√©p√¥t associ√©](https://github.com/InseeFrLab/formation-mlops)).
